{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ChemMatData","text":"<p>The <code>chem_mat_data</code> package provides easy access to a large range of property prediction datasets from Chemistry and Material Science.  The aim of this package is to provide the datasets in a unified format suitable to machine learning applications and specifically to train  graph neural networks (GNNs).</p> <p>Specifically, <code>chem_mat_data</code> addresses these aims by providing simple, single-line command line (CLI) and programming (API) interfaces to download  datasets either in raw or in processed (graph) format.</p> <p>Features:</p> <ul> <li>\ud83d\udc0d Easily installable via <code>pip</code></li> <li>\ud83d\udce6 Instant access to a collection of datasets across the domains of chemistry and material science </li> <li>\ud83e\udd16 Direct support of popular graph deep learning libraries like Torch/PyG and Jax/Jraph</li> <li>\ud83e\udd1d Large python version compatibility</li> <li>\u2328\ufe0f Comprehensive command line interface (CLI)</li> </ul>"},{"location":"api_datasets/","title":"Loading Datasets","text":"<p>In <code>chem_mat_data</code>, each dataset is provided in a raw and a processed/graph format.</p> <p>The raw format resembles the format in which the dataset was originally published in and is  usually more compressed and therefore more storage- and bandwidth-efficient to work with. For molecular  datasets, this raw format usually simply consists of a list of SMILES strings that represents different  molecules and their corresponding target value annotations. Since it is more data efficient, this  format is recommended when working with machine learning methods that do not require the full graph  representation, such as methods based on molecular fingerprints.</p> <p>The processed/graph format contains the already pre-processed full graph information for each molecule  in the dataset. This format represents each molecule as a graph structure where all atoms are represented as  graphs and all bonds as the corresponding edges. This format is recommended for machine learning  methods based on graph neural networks (GNNs) since it removes the time-consuming graph pre-processing step.</p>"},{"location":"api_datasets/#loading-raw-datasets","title":"Loading Raw Datasets","text":""},{"location":"api_datasets/#smiles-dataset","title":"SMILES Dataset","text":"<p>For molecular property prediction tasks, the raw dataset format consists of a list of SMILES strings that  represent the various molecules and their corresponding target value annotations.</p> <p>A raw SMILES dataset can be loaded using the <code>load_smiles_dataset</code> function. This function will return  a <code>pandas.DataFrame</code> object that contains a \"smiles\" column as well as various other columns that contain  the target property annotations (whose names differe between the various datasets.)</p> <pre><code>import pandas as pd\nfrom chem_mat_data import load_smiles_dataset\n\ndf: pd.DataFrame = load_smiles_dataset('clintox')\nprint(df.head())\n</code></pre>"},{"location":"api_datasets/#xyz-datasets","title":"XYZ Datasets","text":"<p>Alternative to SMILES representations, some datasets are stored in the form of .XYZ files.  The main difference of an XYZ dataset w.r.t. to a SMILES dataset is that the SMILES dataset contains the graph structure in the form of the bond  information and the XYZ dataset contains additional geometry information in the form of atom coordinates.</p> <p>A raw XYZ dataset can be loaded using the <code>load_xyz_dataset</code> function. This function will return a  <code>pandas.DataFrame</code> object that most importantly contains the \"mol\" column as well as various other columns that  contain the target property annotations or other additional values.</p> <pre><code>import pandas as pd\nfrom chem_mat_data import load_xyz_dataset\n\ndf: pd.DataFrame = load_xyz_dataset('qm9', parser_cls='qm9')\nprint(df.head())\n</code></pre> <p>Different XYZ File Formats</p> <p>There exist slightly different format specifications for .xyz files which vary in how the include which information. The  <code>parser_cls</code> parameter of the <code>load_xyz_dataset</code> function can be used to specify a distinct parser to be used to load  the dataset in question. To find out which parser to use, one can use the <code>cmdata info</code> command for the dataset in  question.</p>"},{"location":"api_datasets/#loading-processed-datasets","title":"Loading Processed Datasets","text":"<p>The processed/graph format of a dataset can be loaded with the <code>load_graph_dataset</code> function. This function  will return a list of <code>dict</code> objects which contain various key value pairs that describe the full graph  structure of the molecule. For more information on the structure of these graph representations visis the  Graph Representation documentation.</p> <pre><code>from rich.pretty import pprint\nfrom chem_mat_data import load_graph_dataset\n\ngraphs: list[dict] = load_graph_dataset('clintox')\nprint(f'loaded {len(graphs)} graphs')\nexample_graph = graphs[0]\npprint(example_graph)\n</code></pre>"},{"location":"cli_cache/","title":"<code>cache</code> - Interacting with the Local File System Cache","text":"<p>The <code>chem_mat_data</code> package can be used to download various datasets from a remote file share server.  To make sure that datasets only need to be actually downloaded once, the package uses a local file system  cache. Whenever a dataset is downloaded for the first time, the corresponding files are placed in the cache  and if the same dataset is requested again, it is simply copied from the cache rather than downloaded from  the remote server.</p> <p>The <code>cmdata</code> command line interface provides the <code>cache</code> command group to interact with this cache  folder:</p> <pre><code>cmdata cache --help\n</code></pre>"},{"location":"cli_cache/#viewing-the-cache-content","title":"Viewing the Cache Content","text":"<p>To view all the files that are currently stored in the cache, you can use the <code>cache list</code> command:</p> <pre><code>cmdata cache list\n</code></pre> <p>This will print a list view of all the files that are currently stored in the cache directory, divided  by the raw and processed dataset files.</p>"},{"location":"cli_cache/#resetting-the-cache","title":"Resetting the Cache","text":"<p>If you wich to reset the cache for some reason, you can use the <code>cache clear</code> command:</p> <pre><code>cmdata cache clear\n</code></pre> <p>This command will delete all the files in the cache folder.</p>"},{"location":"cli_config/","title":"<code>config</code> - Interacting with the Local Config File","text":"<p>When using the <code>cmdata</code> CLI, a local <code>config.yml</code> file is automatically created in the user's <code>.config</code>  folder. This config file contains certain options that configure the behavior of the package.</p>"},{"location":"cli_config/#viewing-the-config-file","title":"Viewing the Config File","text":"<p>To view the content of the current config file, you can use the <code>config show</code> command:</p> <pre><code>cmdata config show\n</code></pre>"},{"location":"cli_config/#edit-the-config-file","title":"Edit the Config File","text":"<p>To conveniently edit this config file, you can use the <code>config edit</code> command:</p> <pre><code>cmdata config edit\n</code></pre> <p>This command will open the config file using the system's default text editor.</p>"},{"location":"cli_download/","title":"<code>download</code> - Download Dataset","text":"<p>You can use the <code>download</code> command to download the datasets to the local file system by  supplying the unique string identifier of the corresponding dataset (see List Available Datasets):</p> <pre><code>cmdata download \"clintox\"\n</code></pre> <p>This command will download the raw dataset files into the current working directory (CWD). </p>"},{"location":"cli_download/#changing-the-destination-path","title":"Changing the Destination Path","text":"<p>You can change the destination directory for the download using the <code>--path</code> option:</p> <pre><code>cmdata download --path=\"/tmp\" \"clintox\"\n</code></pre>"},{"location":"cli_download/#downloading-the-graph-dataset","title":"Downloading the Graph Dataset","text":"<p>By default the command downloads the raw version of each dataset. You can supply <code>--full</code> flag  to also download the processed/graph version of the dataset as well:</p> <pre><code>cmdata download --full \"clintox\"\n</code></pre> <p>This command will download the raw <code>clintox.csv</code> file and the <code>clintox.mpack</code> file. The processed  dataset is stored in the MessagePack file format, which is essentially  a binary version of the JSON format. When decoding this file with a programming language of choice, it  will yield a list/sequence of graph dictionaries/objects as described in the Graph Representation documentation.</p>"},{"location":"cli_info/","title":"<code>info</code> - Show Dataset Metadata","text":"<p>You can use the <code>info</code> command to view all the metadata associated with a specific dataset by supplying the  unique string identifier of the corresponding dataset (see List Available Datasets)</p> <pre><code>cmdata info \"clintox\"\n</code></pre> <p>This will print a detail view as shown below. The detailed view about the dataset, for example, contains  information about the number of elements it contains, the type of task it presents (regression/classification)  and the description.</p> <p></p>"},{"location":"cli_list/","title":"<code>list</code> - List Available Datasets","text":"<p>You can use the <code>list</code> command to print a list view of all the datasets which are available on the  remote file share server:</p> <pre><code>cmdata list\n</code></pre> <p>This will create a list view as shown below, where each dataset is identified by a unique string name (first column) and  some additional information.</p> <p></p>"},{"location":"custom_pre_processing/","title":"Custom Pre-Processing of Graphs","text":"<p>The <code>chem_mat_data</code> package provides dataset in an already pre-processed graph format. This pre-processed graph  format makes some opinionated choices about which kinds of node and edge features are inlcuded to represent  information about each individual atom or bond in the molecular graph.</p> <p>If this pre-defined format for some reason isn't sufficient for a given dataset, there exists the possibility to  define a custom <code>Processing</code> class to construct a pre-processing pipeline that converts the SMILES representations  into graph structures.</p>"},{"location":"custom_pre_processing/#creating-a-moleculeprocessing-subclass","title":"Creating a <code>MoleculeProcessing</code> Subclass","text":"<p>To define a custom pre-processing structure, one can define a custom subclass of the <code>MoleculeProcessing</code> subclass  and define the desired node and edge features by modifying the <code>node_attributes</code> and <code>edge_attributes</code> class  properties. Both properties have to be dictionary objects that define the node and edge features by providing  a callback function or class that derives the desired property from the corresponding <code>rdkit.Atom</code> or <code>rdkit.Bond</code>  objects.</p> <p>In the following example we can define a customized processing class which only encodes a subset of atom types and  only includes the mass of the atom as an additional feature. For the edge attributes we only encode the difference  between single and double bonds.</p> <pre><code>from chem_mat_data.processing import MoleculeProcessing\nfrom chem_mat_data.processing import OneHotEncoder, chem_prop, list_identity\n\n# Has to inherit from MoleculeProcessing!\nclass CustomProcessing(MoleculeProcessing):\n\n    node_attribute_map = {\n\n        'mass': {\n            # \"chem_prop\" is a wrapper function which will call the given \n            # property method on the rdkit.Atom object - in this case the \n            # GetMass() method - and pass the output to the transformation \n            # function given as the second argument. \"list_identity\" means \n            # that the value is simply converted to a list as it is.\n            # Therefore, this configuration will result in outputs such as \n            # [12.08], [9.88] etc. as parts of the overall feature vector.\n            'callback': chem_prop('GetMass', list_identity),\n            # Provide a human-readable description of what this section of \n            # the node feature vector represents.\n            'description': 'The mass of the atom'\n        },\n\n        'symbol': {\n            # \"OneHotEncoder\" is a special callable class that can be used \n            # to automatically define one-hot encodings. The object will \n            # accept the output of the given chem prop - in this case the \n            # GetSymbol action on the rdkit.Atom - and create an integer \n            # one-hot vector according to the provided list. In this case, \n            # the encoding will encode a carbon as [1, 0, 0, 0], \n            # a oxygen as [0, 1, 0, 0] etc.\n            'callback': chem_prop('GetSymbol', OneHotEncoder(\n                ['C', 'O', 'N', 'S'],\n                add_unknown=False,\n                dtype=str,\n            )),\n            'description': 'One hot encoding of the atom type',\n            'is_type': True,\n            'encodes_symbol': True,\n        },\n    }\n\n    edge_attributes = {\n        'type': {\n            'callback': chem_prop()\n        }\n    }\n</code></pre>"},{"location":"custom_pre_processing/#applying-the-custom-processing","title":"Applying the Custom Processing","text":"<p>After the custom processing class has been defined it can be used in the same manner as the orginal <code>MoleculeProcessing</code>  class to convert the SMILES string representations of the dataset into the graph representation by using the <code>process</code> method.</p> <pre><code>from rich.pretty import pprint\n\nprocessing = CustomProcessing()\n\ngraph: dict = processing.process('CCCC')\npprint(graph)\n</code></pre>"},{"location":"custom_pre_processing/#defining-custom-transformation-callbacks","title":"Defining Custom Transformation Callbacks","text":"<p>As introduced in the previous example, the <code>chem_prop</code> wrapper can be used to cast the output of an <code>rdkit.Atom</code> or  <code>rdkit.Bond</code> atom to some transformation callback which is then supposed to return a list that will become part  of the final node/edge feature vector. </p> <p>The most simple usage is the <code>list_identity</code> transformation which will simply wrap the output value in a list as it is. An alternative is to use the existing OneHotEncoder class to convert the output of a property getter method into an  integer one-hot encoded vector.</p> <p>Alternatively, it is also possible to define a completely custom callback to derive properties from the atom / bond  objects directly. The callback functions simply have to accept a single positional argument <code>entity: Atom | Bond</code>.  callback function has to return a list of numeric values which will be appended to the overall feature vector.</p> <pre><code>import rdkit.Chem as Chem\nfrom rich.pretty import pprint\nfrom typing import List\nfrom chem_mat_data.processing import MoleculeProcessing\n\ndef custom_callback(atom: Chem.Atom) -&gt; List[float]:\n\n    # Mass multiplied with the charge\n    return [atom.GetMass() * atom.GetCharge()]\n\n\nclass CustomCallbackProcessing(MoleculeProcessing):\n\n    node_attributes = {\n        'mass_times_charge': {\n            'callback': custom_callback,\n            'description': 'atom mass multiplied with the charge',\n        }\n    }\n\n\nprocessing = CustomCallbackProcessing()\ngraph = processing.process('CCCC')\npprint(graph)\n</code></pre>"},{"location":"datasets/","title":"Datasets","text":"<p>Currently the database is hosted on the following remote file share server:  https://bwsyncandshare.kit.edu/s/98NgmGCDty54kik/download/.</p>"},{"location":"datasets/#available-datasets","title":"Available Datasets","text":"<p>The following datasets can be downloaded either using the command line interface (CLI) or directly  using the python API.</p> Name Description No. Elements Target Type MCF_7 - 26776 regression _price_small - 80000 _test - 3 Regression _test2 - 3 Regression ames Ames Mutagenicity Assays 6512 Classification aqsoldb Aqueous Solubility 9889 Regression bace BACE-1 Binding Affinity 1513 Regression, Classification bbbp Blood-Brain Barrier Penetration 1934 Classification beet Honey Bee Toxicity 254 Classification clintox Clinical Toxicity 1465 Classification compas_1x DFT properties of polycyclic aromatic hydrocarbons 34072 Regression compas_3x DFT properties of polycyclic aromatic hydrocarbons 39482 Regression dpp4 DPP-4 inhibitors 3933 Classification elanos_bp Boiling Point 5431 regression elanos_vp Vapor Pressure 2704 regression esol Water Solubility 1127 Regression freesolv Hydration Free Energy 639 Regression hiv HIV Inhibitors 38040 Classification lipophilicity Octanol/Water Distribution Coefficient 4199 Regression muv MUV Benchmark 93087 Classification pcqm4mv2 - 3378606 Regression qm9 DFT properties of small molecules 134000 Regression qm9_smiles DFT properties of small molecules 133882 Regression sider Drug Side Effects 1220 Classification skin_irritation Skin Irritation 1263 classification skin_sensitizers Skin Sensitization 1263 classification synth_binary_global - 249455 Classification synth_binary_local - 249455 Classification tox21 Toxicology 7570 Classification toxcast Toxicology 6842 Classification"},{"location":"first_steps/","title":"First Steps","text":""},{"location":"first_steps/#command-line-interface-cli","title":"Command Line Interface (CLI)","text":"<p>After installing the <code>chem_mat_data</code> package, you should have access to the <code>cmdata</code> command line interface which  allows to interact with the remote file share server to, for example, list all the available datasets or to download  them into a local directory.</p>"},{"location":"first_steps/#help-option","title":"Help Option","text":"<p>You can use the <code>--help</code> option to get a list of all the available commands:</p> <pre><code>cmdata --help\n</code></pre>"},{"location":"first_steps/#simple-commands","title":"Simple Commands","text":"<p>To view a list of all the available datasets on the remote file share server, you can use the <code>list</code> command:</p> <pre><code>cmdata list\n</code></pre> <p>This command will produce a list view as shown below</p> <p></p> <p>You can then use the <code>download</code> command to download one of the datasets by using its unique string name:</p> <pre><code>cmdata download \"clintox\"\n</code></pre> <p>This command will, for example, download a raw <code>clintox.csv</code> file into the current working directory. This raw  CSV dataset format consists of a list of SMILES molecule representations and their corresponding target value  annotations - in this case a classification label of the molecules toxicity.</p>"},{"location":"first_steps/#programming-interface-api","title":"Programming Interface (API)","text":"<p>Alternatively, the <code>chem_mat_data</code> functionality can be used programmatically as part of python code. The  package provides each dataset either in raw or processed/graph format (For further information on the  distincation visit the Loading Datasets) documentation.</p>"},{"location":"first_steps/#raw-datasets","title":"Raw Datasets","text":"<p>You can use the <code>load_smiles_dataset</code> function to download the raw dataset format. This function will  return the dataset as a <code>pandas.DataFrame</code> object which contains a \"smiles\" column along with the specific  target value annotations as separate data frame columns.</p> <pre><code>import pandas as pd\nfrom chem_mat_data import load_smiles_dataset\n\ndf: pd.DataFrame = load_smiles_dataset('clintox')\nprint(df.head())\n</code></pre>"},{"location":"first_steps/#graph-datasets","title":"Graph Datasets","text":"<p>You can also use the <code>load_graph_dataset</code> function to download the same dataset in the pre-processed graph  representation. This function will return a list of <code>dict</code> objects which contain the full graph representation  of the corresponding molecules.</p> <pre><code>from rich.pretty import pprint\nfrom chem_mat_data import load_graph_dataset\n\ngraphs: list[dict] = load_graph_dataset('clintox')\nexample_graph = graphs[0]\npprint(example_graph)\n</code></pre> <p>For more details on the structure of this graph representation, please refer to the  Graph Representation documentation.</p> <p>(Insert an example of how to train a PyG model with this representation)</p>"},{"location":"graph_representation/","title":"Graph Representation","text":"<p>The <code>chem_mat_data</code> package provides various chemical property prediction datasets in a pre-processed format,  in which molecules are mapped to graph structures that represent the atoms as nodes and the bonds as corresponding  edges.</p>"},{"location":"graph_representation/#graph-dict-structure","title":"Graph Dict Structure","text":"<p>Practically, this graph structure is represented as a native python <code>dict</code> object with a set of specific attributes.</p> <p>Generally, the graph dict structure follows the following naming convention</p> <ul> <li>Prefix <code>node_</code> for node-level attributes with shape \\((V, ?)\\)</li> <li>Prefix <code>edge_</code> for edge-level attributes with shape \\((E, ?)\\)</li> <li>Prefix <code>graph_</code> for graph-level attributes with shape \\((?, )\\)</li> </ul> <p>More specifically, each graph dict object has the following minimal set of attributes:</p> Attribute Description <code>node_indices</code> Integer numpy array of shape \\((V, )\\) where \\(V\\) is the number of nodes in the graph. Contains the unique integer indices of the graph nodes. <code>node_attributes</code> Float numpy array of shape \\((V, N)\\) where \\(V\\) is the number of nodes and \\(N\\) is the number of numeric node features. Contains the numeric feature vectors that represent each node. <code>edge_indices</code> Integer numpy array of shape \\((E, 2)\\) where \\(E\\) is the number of edges in the graph. Contains tuples \\((i, j)\\) of node indices that indicate the existence of an edge between nodes \\(i\\) and \\(j\\). <code>edge_attributes</code> Float numpy array of shape \\((E, M)\\) where \\(E\\) is the number of edges in the graph and \\(M\\) is the number of values in the graph. <code>graph_labels</code> Float numpy array of shape \\((T, )\\) where \\(T\\) is the number of target values associated with each element of the dataset. The target values can either be continuous regression targets such as <code>[1.43, -9.4]</code> or could be one-hot classification labels such as <code>[0, 1, 0]</code>. <code>graph_repr</code> The string numpy array of shape \\((1, )\\) containing the string SMILES representation of the original molecule. <p>Depending on the dataset, the graph dict representation may contain additional attributes that represent custom properties such as the 3D coordinates of nodes/atoms, for exmaple.</p>"},{"location":"graph_representation/#default-features","title":"Default Features","text":"<p>The graph representations that can be downloaded already come with a pre-defined encoding of numeric node and edge feature vectors that encode specific information about the atoms and bonds of the molecular graphs. The selection of which attributes are included here is pre-determined to be a basic selection of attributes which will be explained in detail in the following sections.</p> <p>All features were calculated based on the <code>rdkit.Mol</code> representation of the corresponding elements.</p> <p>If the default feature selection is for some reason insufficient for a given task, there is the option to define custom pre-processing classes with a  custom selection of features. Custom Pre-Processing</p>"},{"location":"graph_representation/#node-features","title":"Node Features","text":"<p>The standard node features are the following:</p> Feature Index Name Description \\(0\\) is Carbon (C)? Integer one-hot label if the node represents a carbon atom. \\(1\\) is Oxygen (O)? Integer one-hot label if the node represents an oxygen atom. \\(2\\) is Nitrogen (N)? Integer one-hot label if the node represents a nitrogen atom. \\(3\\) is Sulfur (S)? Integer one-hot label if the node represents a sulfur atom. \\(4\\) is Phosphorus (P)? Integer one-hot label if the node represents a phosphorus atom. \\(5\\) is Fluorine (F)? Integer one-hot label if the node represents a fluorine atom. \\(6\\) is Chlorine (Cl)? Integer one-hot label if the node represents a chlorine atom. \\(7\\) is Bromine (Br)? Integer one-hot label if the node represents a bromine atom. \\(8\\) is Iodine (I)? Integer one-hot label if the node represents an iodine atom. \\(9\\) is Silicon (Si)? Integer one-hot label if the node represents a silicon atom. \\(10\\) is Boron (B)? Integer one-hot label if the node represents a boron atom. \\(11\\) is Sodium (Na)? Integer one-hot label if the node represents a sodium atom. \\(12\\) is Magnesium (Mg)? Integer one-hot label if the node represents a magnesium atom. \\(13\\) is Calcium (Ca)? Integer one-hot label if the node represents a calcium atom. \\(14\\) is Iron (Fe)? Integer one-hot label if the node represents an iron atom. \\(15\\) is Aluminum (Al)? Integer one-hot label if the node represents an aluminum atom. \\(16\\) is Copper (Cu)? Integer one-hot label if the node represents a copper atom. \\(17\\) is Zinc (Zn)? Integer one-hot label if the node represents a zinc atom. \\(18\\) is Potassium (K)? Integer one-hot label if the node represents a potassium atom. \\(19\\) is Uknown atom? Integer one-hot label for an unknown atom type not covered by the above list of atoms. \\(20\\) S hybrid Integer one-hot label if the atom has S hybridization. \\(21\\) SP hybrid Integer one-hot label if the atom has SP hybridization. \\(22\\) SP2 hybrid Integer one-hot label if the atom has SP2 hybridization. \\(23\\) SP3 hybrid Integer one-hot label if the atom has SP3 hybridization. \\(24\\) SP2D hybrid Integer one-hot label if the atom has SP2D hybridization. \\(25\\) SP3D hybrid Integer one-hot label if the atom has SP3D hybridization. \\(26\\) Unknown hybridization Integer one-hot label for an unknown hybridization type not covered by the above list. \\(27\\) 0 Neighbors Integer one-hot label if the atom has 0 neighbors. \\(28\\) 1 Neighbor Integer one-hot label if the atom has 1 neighbor. \\(29\\) 2 Neighbors Integer one-hot label if the atom has 2 neighbors. \\(30\\) 3 Neighbors Integer one-hot label if the atom has 3 neighbors. \\(31\\) 4 Neighbors Integer one-hot label if the atom has 4 neighbors. \\(32\\) 5 Neighbors Integer one-hot label if the atom has 5 neighbors. \\(33\\) 0 Hydrogens Integer one-hot label if the atom has 0 attached hydrogen atoms. \\(34\\) 1 Hydrogen Integer one-hot label if the atom has 1 attached hydrogen atom. \\(35\\) 2 Hydrogens Integer one-hot label if the atom has 2 attached hydrogen atoms. \\(36\\) 3 Hydrogens Integer one-hot label if the atom has 3 attached hydrogen atoms. \\(37\\) 4 Hydrogens Integer one-hot label if the atom has 4 attached hydrogen atoms. \\(38\\) Mass Float value representing the mass of the atom. \\(39\\) Charge Integer value representing the electrical charge of the atom. \\(40\\) Is Aromatic? Integer one-hot label if the atom is aromatic. \\(41\\) Is in Ring? Integer one-hot label if the atom is in a ring. \\(42\\) Crippen Contributions Float value representing the Crippen logP contributions of the atom as computed by RDKit."},{"location":"graph_representation/#edge-features","title":"Edge Features","text":"<p>The standard edge features are the following:</p> Feature Index Name Description \\(0\\) Single Bond One hot encoding if the bond is a single bond. \\(1\\) Double Bond One hot encoding if the bond is a double bond. \\(2\\) Triple Bond One hot encoding if the bond is a triple bond. \\(3\\) Aromatic Bond One hot encoding if the bond is an aromatic bond. \\(4\\) Ionic Bond One hot encoding if the bond is an ionic bond. \\(5\\) Hydrogen Bond One hot encoding if the bond is a hydrogen bond. \\(6\\) Unknown Bond One hot encoding if the bond type is unknown. \\(7\\) Stereo None One hot encoding if the bond has no stereo property. \\(8\\) Stereo Any One hot encoding if the bond has any stereo property. \\(9\\) Stereo Z One hot encoding if the bond has Z stereo property. \\(10\\) Stereo E One hot encoding if the bond has E stereo property. \\(11\\) Is Aromatic Integer flag if the bond is aromatic. \\(12\\) Is in Ring Integer flag if the bond is part of a ring. \\(13\\) Is Conjugated Integer flag if the bond is conjugated."},{"location":"installation/","title":"Installation","text":"<p>You can install the latest stable version from the Python Package Index (PyPi) like this:</p> <pre><code>uv pip install chem_mat_data\n</code></pre> <p>Warning</p> <p>The stable version of the package is not yet officially released. For the time being, please use the source installation from the github repository.</p> <p>Alternatively, you can install the latest development version of the package directly from the Github repository:</p> <pre><code>uv pip install git+https://github.com/the16thpythonist/chem_mat_data\n</code></pre> <p>Check your installation. Installing the package should provide access to the <code>cmdata</code> command line interface. You can check this with the following command, which should print the current version of the <code>chem_mat_data</code> package:</p> <pre><code>cmdata --version\n</code></pre>"},{"location":"processing_graphs/","title":"Processing New Graphs","text":"<p>The <code>chem_mat_data</code> package provides a pre-processed graph format in which the individual  molecules of a dataset can directly be loaded in a full graph representation with numeric node and  edge feature vectors to specifically simplify the training of graph neural network (GNN) models.</p> <p>Assuming one trains a GNN model on such a pre-processed dataset, one might also want to use such  a model for inference to predict the target properties of new elements which weren't in the  initial dataset. In such a case, the new elements will have to be processed into the same graph  format to be compatible to be used as input to the trained model.</p> <p>To process new graphs into the same graph format, one can use the package's <code>MoleculeProcessing</code> class.  The <code>process</code> method of such a processing instance takes a molecule SMILES string representation as  an input and returns the corresponding graph dict representation:</p> <pre><code>from rich.pretty import pprint\nfrom chem_mat_data.processing import MoleculeProcessing\n\nprocessing = MoleculeProcessing()\n\nsmiles: str = 'C1=CC=CC=C1CCN'\ngraph: dict = processing.process(smiles)\npprint(graph)\n</code></pre>"},{"location":"architecture_decisions/001_providing_processed_datasets/","title":"Providing Processed Datasets","text":""},{"location":"architecture_decisions/001_providing_processed_datasets/#status","title":"Status","text":"<p>implemented</p>"},{"location":"architecture_decisions/001_providing_processed_datasets/#context","title":"Context","text":"<p>The <code>chem_mat_data</code> package mainly aims to provide a Python and command line API which can be used to easily  download and access chemistry and material science datasets for machine learning with a specific focus on  graph neural networks. One core question in the design of this package is in which format to provide these  datasets to the end user. This is a tricky matter because the datasets may have slightly different formats  themselves and might even have slighlty different objectives. For example, there can be a distinction between  node-level and graph-level tasks which changes the way in which the ground truth labels have to be provided.  Another difference could be that some datasets may consists of different molecules while other datasets consist  of the same molecule over and over again, only with different geometries.</p>"},{"location":"architecture_decisions/001_providing_processed_datasets/#decision","title":"Decision","text":"<p>The decision made for this package is to provide datasets in two formats simultaneously: - raw. This format should be as close as possible to the original domain-specific representation that the    dataset is provided in. For most datasets this will likely be a CSV file containing the SMILES codes of    different molecules associated with ground truth classification and regression labels. Additionally, this    raw representation could be extended with additional information about the geometric configurations. - processed. In addition to the raw format, each dataset should also be provided in the already processed    format. In this format, the individual elements of the dataset are already present as abstract graph    structures consisting of nodes (atoms) connected by edges (bonds). Additionally each node and edge should    be associated with a numeric feature vector which has been extracted using the Cheminformatics library    <code>RDKit</code>.</p>"},{"location":"architecture_decisions/001_providing_processed_datasets/#consequences","title":"Consequences","text":""},{"location":"architecture_decisions/001_providing_processed_datasets/#advantages","title":"Advantages","text":"<p>Ease of use. The main advantage of providing the processed version of the dataset directly is that this makes  it immensly easy to use the dataset to train a graph neural network. The graph format used in the package is a  generic one and the package specifically aims to provide adapters that transform these generic graph structures  into the necessary object instances required for the most common graph learning libraries such as pytorch geometric  and jraph. This ultimately means that a dataset is training-ready in a couple lines of code.</p> <p>Standardization. The processed graph structures already contain numeric feature vectors for the nodes and edges  which have been obtained from RDKit. If everyone were to use the same processing / featurization pipeline, this would  lead to more comparable results in the end.</p>"},{"location":"architecture_decisions/001_providing_processed_datasets/#disadvantages","title":"Disadvantages","text":"<p>Dataset size. A main disadvantage of the processed datasets is the significantly increased size required  to encode the full graph structure which will affect the download speed and the storage requirements especially  for larger datasets.</p> <p>Rigidity. The processed graph structures already contain numeric feature vectors for the nodes and edges  which have been obtained from RDKit. Besides a standardization effect, this also means that. However, the package also provides the means to implement custom processing on top of the raw dataset  representations if desired.</p>"},{"location":"architecture_decisions/002_custom_graph_represention/","title":"Custom Graph Representation","text":""},{"location":"architecture_decisions/002_custom_graph_represention/#status","title":"Status","text":"<p>implemented</p>"},{"location":"architecture_decisions/002_custom_graph_represention/#context","title":"Context","text":"<p>The package also provides the various datasets to be downloaded in a processed format where the  various molecules are in a generic graph representation. The question that arises in this situation  is how to structure this graph representation, especially since different datasets may have different  requirements.</p> <p>The main requirements for this graph representation are: - support for rich metadata at each level of the graph: node-, edge- and graph-level - support for graph-level feature and label annotations - support for node-level feature vectors - support for edge-level feature vectors</p>"},{"location":"architecture_decisions/002_custom_graph_represention/#decision","title":"Decision","text":"<p>The decision is to use a custom graph representation specifically created by and for this package called  a GraphDict representation. This represents a graph as a simple python native dictionary structure where  special keys identify the various parts of the graph representation. The most important keys are the following:</p> <ul> <li><code>node_indices</code>: The integer indices of the nodes</li> <li><code>node_attributes</code>: A node feature vector for each node in the same order as the node indices</li> <li><code>edge_indices</code>: a list of node index tuples which define which nodes are connected by edges</li> <li><code>edge_attributes</code>: A edge feature vector for each edge in the same order as the edge indices</li> <li><code>graph_labels</code>: A list of label annotations for the graph as a whole</li> </ul> <p>Besides these main keys, the primary feature of the graph dict representation is that it is supposed to be  flexible and that additional properties can be added dynamically by using one of the special prefixes  <code>node_</code>, <code>edge_</code> and <code>graph_</code> to indicate at which level of the graph to attach the information  to.</p>"},{"location":"architecture_decisions/002_custom_graph_represention/#consequences","title":"Consequences","text":""},{"location":"architecture_decisions/002_custom_graph_represention/#advantages","title":"Advantages","text":"<p>Native. The major advantage of this graph representation is that it only relies on python native  datastructures such as dictionaries and lists and by extension is therefore also easily JSON encodable.  Being able to JSON encode is very important for the transfer of the datasets over the internet and  also the potential compatibility with other programming languages when compared to a pickle dump for  example. </p> <p>Generic and Flexible. The flexible format allows to add additional information for datasets that  need it without having to over-complicate the core data structure.</p>"},{"location":"architecture_decisions/002_custom_graph_represention/#disadvantages","title":"Disadvantages","text":"<p>Custom Format. It is a custom format that most people will not be initially familiar with. This is  in contrast to using more common formats such as networkx Graph instances for example, which some  people might already have familarity with. However, we argue that the format is simple enough to  understand and also simple enough to convert to a more common format such as networkx - especially if  the necessary adapaters are provided as part of the package as well.</p>"},{"location":"architecture_decisions/003_local_dataset_cache/","title":"Local Dataset Cache","text":""},{"location":"architecture_decisions/003_local_dataset_cache/#status","title":"Status","text":"<p>implemented</p>"},{"location":"architecture_decisions/003_local_dataset_cache/#context","title":"Context","text":"<p>The ChemMatData package provides the possibility to download graph datasets from a remote file share  server. These datasets can either be in the \"raw\" format - in the case of purely molecular datasets  this usually means a CSV file with the molecule SMILES representations annotated with the target values. But more importantly, these datasets can be downloaded in the already pre-processed format and easily  loaded into the popular graph deep learning libraries.</p> <p>There exists a command line interface and a programming interface to very easily load a dataset with a  single function call. The problem now is that repeated calls to this function would download the dataset  anew each time. This would require a constant internet connection and could take a significant amount of  time for larger datasets.</p>"},{"location":"architecture_decisions/003_local_dataset_cache/#decision","title":"Decision","text":"<p>The mitigate the recurring runtime of re-downloading the datasets each time, a local caching mechanism was  added which was inspired by package managers such as <code>pip</code> which also maintain a similar caching mechanism. Whenever a dataset is downloaded, the downloaded files will be placed into a user-specific caching folder.  For all subsequent retrievals of the dataset, the cached version will be used instead.</p> <p>Inside the cache, each dataset is enumerated by its unique string name and the dataset type (raw or processed).</p>"},{"location":"architecture_decisions/003_local_dataset_cache/#consequences","title":"Consequences","text":""},{"location":"architecture_decisions/003_local_dataset_cache/#advantages","title":"Advantages","text":"<p>Runtime. The clear advantage of a local cache is the runtime. Especially for large datasert and/or repeated  execution of the dataset loading functionality, a local cahce will result in a clear reduction in runtime and  bandwith.</p>"},{"location":"architecture_decisions/003_local_dataset_cache/#disadvantages","title":"Disadvantages","text":"<p>User Storage. For the user, the cache will eat up some storage capacity, which may or may not be significant  depending on the number and size of the stored datasets. Although, this likely won't be a problem as the archived  versions of even the largest datasets currently do now exceed a GB in size.</p> <p>Management Overhead. On the development side, the cache introduces another layer of complexity. Before fetching  the datasets, we need to check if the dataset exists in the cache and after downloading the dataset we need to  add the dataset to the cache.</p>"}]}